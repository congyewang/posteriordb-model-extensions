# return(fit$par)
return(fit)
}
bootstrap_prediction_interval <- function(Y, params_hat, B = 1000, alpha = 0.05) {
n <- length(Y)
residuals <- numeric(n - 1)
last_residual <- NA
for (t in 2:n) {
if (Y[t] == Y[t - 1]) {
residuals[t - 1] <- last_residual
} else {
mean_cond <- params_hat[2] + exp(-params_hat[1]) * (Y[t - 1] - params_hat[2])
residuals[t - 1] <- Y[t] - mean_cond
last_residual <- residuals[t - 1]
}
}
bootstrap_samples <- matrix(NA, nrow = B, ncol = n - 1)
for (b in 1:B) {
resampled_residuals <- sample(residuals, size = n - 1, replace = TRUE)
bootstrap_samples[b, ] <- resampled_residuals
}
lower <- numeric(n - 1)
upper <- numeric(n - 1)
for (t in 1:(n - 1)) {
lower[t] <- quantile(bootstrap_samples[, t], probs = alpha / 2, na.rm = TRUE)
upper[t] <- quantile(bootstrap_samples[, t], probs = 1 - alpha / 2, na.rm = TRUE)
}
return(list(lower = lower, upper = upper))
}
# Main execution
set.seed(123)
n <- 1000
theta <- 0.2
mu <- 1
sigma2 <- 0.1
omega2 <- 0.5
# Simulate data
Y <- simulate_ou_process(n, theta, mu, sigma2, omega2)
# Check data validity
if (any(!is.finite(Y))) stop("Data Y contains non-finite values.")
# Estimate parameters
res <- estimate_parameters(Y)
params_hat <- res$par
# Estimate parameters using MLE with safeguards
estimate_parameters <- function(Y) {
# Initialize parameters
init_params <- c(0.1809536, mean(Y), var(Y), 0.000001)
# Optimization
fit <- optim(
par = init_params,
fn = neg_log_likelihood,
Y = Y,
method = "CG",
# lower = c(0, -Inf, 1e-6, 1e-6),  # Parameter constraints
# lower = c(0, -Inf, 1e-6, 1e-20),
# upper = c(Inf, Inf, Inf, Inf)
)
if (fit$convergence != 0) stop("Optimization did not converge.")
# return(fit$par)
return(fit)
}
bootstrap_prediction_interval <- function(Y, params_hat, B = 1000, alpha = 0.05) {
n <- length(Y)
residuals <- numeric(n - 1)
last_residual <- NA
for (t in 2:n) {
if (Y[t] == Y[t - 1]) {
residuals[t - 1] <- last_residual
} else {
mean_cond <- params_hat[2] + exp(-params_hat[1]) * (Y[t - 1] - params_hat[2])
residuals[t - 1] <- Y[t] - mean_cond
last_residual <- residuals[t - 1]
}
}
bootstrap_samples <- matrix(NA, nrow = B, ncol = n - 1)
for (b in 1:B) {
resampled_residuals <- sample(residuals, size = n - 1, replace = TRUE)
bootstrap_samples[b, ] <- resampled_residuals
}
lower <- numeric(n - 1)
upper <- numeric(n - 1)
for (t in 1:(n - 1)) {
lower[t] <- quantile(bootstrap_samples[, t], probs = alpha / 2, na.rm = TRUE)
upper[t] <- quantile(bootstrap_samples[, t], probs = 1 - alpha / 2, na.rm = TRUE)
}
return(list(lower = lower, upper = upper))
}
# Main execution
set.seed(123)
n <- 1000
theta <- 0.2
mu <- 1
sigma2 <- 0.1
omega2 <- 0.5
# Simulate data
Y <- simulate_ou_process(n, theta, mu, sigma2, omega2)
# Check data validity
if (any(!is.finite(Y))) stop("Data Y contains non-finite values.")
# Estimate parameters
res <- estimate_parameters(Y)
# Estimate parameters using MLE with safeguards
estimate_parameters <- function(Y) {
# Initialize parameters
init_params <- c(0.1809536, mean(Y), var(Y), 0.000001)
# Optimization
fit <- optim(
par = init_params,
fn = neg_log_likelihood,
Y = Y,
method = "warn.1d.NelderMead",
# lower = c(0, -Inf, 1e-6, 1e-6),  # Parameter constraints
lower = c(0, -Inf, 1e-6, 1e-20),
upper = c(Inf, Inf, Inf, Inf)
)
if (fit$convergence != 0) stop("Optimization did not converge.")
# return(fit$par)
return(fit)
}
bootstrap_prediction_interval <- function(Y, params_hat, B = 1000, alpha = 0.05) {
n <- length(Y)
residuals <- numeric(n - 1)
last_residual <- NA
for (t in 2:n) {
if (Y[t] == Y[t - 1]) {
residuals[t - 1] <- last_residual
} else {
mean_cond <- params_hat[2] + exp(-params_hat[1]) * (Y[t - 1] - params_hat[2])
residuals[t - 1] <- Y[t] - mean_cond
last_residual <- residuals[t - 1]
}
}
bootstrap_samples <- matrix(NA, nrow = B, ncol = n - 1)
for (b in 1:B) {
resampled_residuals <- sample(residuals, size = n - 1, replace = TRUE)
bootstrap_samples[b, ] <- resampled_residuals
}
lower <- numeric(n - 1)
upper <- numeric(n - 1)
for (t in 1:(n - 1)) {
lower[t] <- quantile(bootstrap_samples[, t], probs = alpha / 2, na.rm = TRUE)
upper[t] <- quantile(bootstrap_samples[, t], probs = 1 - alpha / 2, na.rm = TRUE)
}
return(list(lower = lower, upper = upper))
}
# Main execution
set.seed(123)
n <- 1000
theta <- 0.2
mu <- 1
sigma2 <- 0.1
omega2 <- 0.5
# Simulate data
Y <- simulate_ou_process(n, theta, mu, sigma2, omega2)
# Check data validity
if (any(!is.finite(Y))) stop("Data Y contains non-finite values.")
# Estimate parameters
res <- estimate_parameters(Y)
# Estimate parameters using MLE with safeguards
estimate_parameters <- function(Y) {
# Initialize parameters
init_params <- c(0.1809536, mean(Y), var(Y), 0.000001)
# Optimization
fit <- optim(
par = init_params,
fn = neg_log_likelihood,
Y = Y,
method = "Nelder-Mead",
# lower = c(0, -Inf, 1e-6, 1e-6),  # Parameter constraints
lower = c(0, -Inf, 1e-6, 1e-20),
upper = c(Inf, Inf, Inf, Inf)
)
if (fit$convergence != 0) stop("Optimization did not converge.")
# return(fit$par)
return(fit)
}
bootstrap_prediction_interval <- function(Y, params_hat, B = 1000, alpha = 0.05) {
n <- length(Y)
residuals <- numeric(n - 1)
last_residual <- NA
for (t in 2:n) {
if (Y[t] == Y[t - 1]) {
residuals[t - 1] <- last_residual
} else {
mean_cond <- params_hat[2] + exp(-params_hat[1]) * (Y[t - 1] - params_hat[2])
residuals[t - 1] <- Y[t] - mean_cond
last_residual <- residuals[t - 1]
}
}
bootstrap_samples <- matrix(NA, nrow = B, ncol = n - 1)
for (b in 1:B) {
resampled_residuals <- sample(residuals, size = n - 1, replace = TRUE)
bootstrap_samples[b, ] <- resampled_residuals
}
lower <- numeric(n - 1)
upper <- numeric(n - 1)
for (t in 1:(n - 1)) {
lower[t] <- quantile(bootstrap_samples[, t], probs = alpha / 2, na.rm = TRUE)
upper[t] <- quantile(bootstrap_samples[, t], probs = 1 - alpha / 2, na.rm = TRUE)
}
return(list(lower = lower, upper = upper))
}
# Main execution
set.seed(123)
n <- 1000
theta <- 0.2
mu <- 1
sigma2 <- 0.1
omega2 <- 0.5
# Simulate data
Y <- simulate_ou_process(n, theta, mu, sigma2, omega2)
# Check data validity
if (any(!is.finite(Y))) stop("Data Y contains non-finite values.")
# Estimate parameters
res <- estimate_parameters(Y)
# Estimate parameters using MLE with safeguards
estimate_parameters <- function(Y) {
# Initialize parameters
init_params <- c(0.1809536, mean(Y), var(Y), 0.000001)
# Optimization
fit <- optim(
par = init_params,
fn = neg_log_likelihood,
Y = Y,
method = "Nelder-Mead"
# lower = c(0, -Inf, 1e-6, 1e-6),  # Parameter constraints
# lower = c(0, -Inf, 1e-6, 1e-20),
# upper = c(Inf, Inf, Inf, Inf)
)
if (fit$convergence != 0) stop("Optimization did not converge.")
# return(fit$par)
return(fit)
}
bootstrap_prediction_interval <- function(Y, params_hat, B = 1000, alpha = 0.05) {
n <- length(Y)
residuals <- numeric(n - 1)
last_residual <- NA
for (t in 2:n) {
if (Y[t] == Y[t - 1]) {
residuals[t - 1] <- last_residual
} else {
mean_cond <- params_hat[2] + exp(-params_hat[1]) * (Y[t - 1] - params_hat[2])
residuals[t - 1] <- Y[t] - mean_cond
last_residual <- residuals[t - 1]
}
}
bootstrap_samples <- matrix(NA, nrow = B, ncol = n - 1)
for (b in 1:B) {
resampled_residuals <- sample(residuals, size = n - 1, replace = TRUE)
bootstrap_samples[b, ] <- resampled_residuals
}
lower <- numeric(n - 1)
upper <- numeric(n - 1)
for (t in 1:(n - 1)) {
lower[t] <- quantile(bootstrap_samples[, t], probs = alpha / 2, na.rm = TRUE)
upper[t] <- quantile(bootstrap_samples[, t], probs = 1 - alpha / 2, na.rm = TRUE)
}
return(list(lower = lower, upper = upper))
}
# Main execution
set.seed(123)
n <- 1000
theta <- 0.2
mu <- 1
sigma2 <- 0.1
omega2 <- 0.5
# Simulate data
Y <- simulate_ou_process(n, theta, mu, sigma2, omega2)
# Check data validity
if (any(!is.finite(Y))) stop("Data Y contains non-finite values.")
# Estimate parameters
res <- estimate_parameters(Y)
res
# Estimate parameters using MLE with safeguards
estimate_parameters <- function(Y) {
# Initialize parameters
init_params <- c(0.1809536, mean(Y), var(Y), 0.5)
# Optimization
fit <- optim(
par = init_params,
fn = neg_log_likelihood,
Y = Y,
method = "Nelder-Mead"
# lower = c(0, -Inf, 1e-6, 1e-6),  # Parameter constraints
# lower = c(0, -Inf, 1e-6, 1e-20),
# upper = c(Inf, Inf, Inf, Inf)
)
if (fit$convergence != 0) stop("Optimization did not converge.")
# return(fit$par)
return(fit)
}
bootstrap_prediction_interval <- function(Y, params_hat, B = 1000, alpha = 0.05) {
n <- length(Y)
residuals <- numeric(n - 1)
last_residual <- NA
for (t in 2:n) {
if (Y[t] == Y[t - 1]) {
residuals[t - 1] <- last_residual
} else {
mean_cond <- params_hat[2] + exp(-params_hat[1]) * (Y[t - 1] - params_hat[2])
residuals[t - 1] <- Y[t] - mean_cond
last_residual <- residuals[t - 1]
}
}
bootstrap_samples <- matrix(NA, nrow = B, ncol = n - 1)
for (b in 1:B) {
resampled_residuals <- sample(residuals, size = n - 1, replace = TRUE)
bootstrap_samples[b, ] <- resampled_residuals
}
lower <- numeric(n - 1)
upper <- numeric(n - 1)
for (t in 1:(n - 1)) {
lower[t] <- quantile(bootstrap_samples[, t], probs = alpha / 2, na.rm = TRUE)
upper[t] <- quantile(bootstrap_samples[, t], probs = 1 - alpha / 2, na.rm = TRUE)
}
return(list(lower = lower, upper = upper))
}
# Main execution
set.seed(123)
n <- 1000
theta <- 0.2
mu <- 1
sigma2 <- 0.1
omega2 <- 0.5
# Simulate data
Y <- simulate_ou_process(n, theta, mu, sigma2, omega2)
# Check data validity
if (any(!is.finite(Y))) stop("Data Y contains non-finite values.")
# Estimate parameters
res <- estimate_parameters(Y)
res
# Estimate parameters using MLE with safeguards
estimate_parameters <- function(Y) {
# Initialize parameters
init_params <- c(0.18, mean(Y), var(Y), 0.4)
# Optimization
fit <- optim(
par = init_params,
fn = neg_log_likelihood,
Y = Y,
method = "Nelder-Mead"
# lower = c(0, -Inf, 1e-6, 1e-6),  # Parameter constraints
# lower = c(0, -Inf, 1e-6, 1e-20),
# upper = c(Inf, Inf, Inf, Inf)
)
if (fit$convergence != 0) stop("Optimization did not converge.")
# return(fit$par)
return(fit)
}
bootstrap_prediction_interval <- function(Y, params_hat, B = 1000, alpha = 0.05) {
n <- length(Y)
residuals <- numeric(n - 1)
last_residual <- NA
for (t in 2:n) {
if (Y[t] == Y[t - 1]) {
residuals[t - 1] <- last_residual
} else {
mean_cond <- params_hat[2] + exp(-params_hat[1]) * (Y[t - 1] - params_hat[2])
residuals[t - 1] <- Y[t] - mean_cond
last_residual <- residuals[t - 1]
}
}
bootstrap_samples <- matrix(NA, nrow = B, ncol = n - 1)
for (b in 1:B) {
resampled_residuals <- sample(residuals, size = n - 1, replace = TRUE)
bootstrap_samples[b, ] <- resampled_residuals
}
lower <- numeric(n - 1)
upper <- numeric(n - 1)
for (t in 1:(n - 1)) {
lower[t] <- quantile(bootstrap_samples[, t], probs = alpha / 2, na.rm = TRUE)
upper[t] <- quantile(bootstrap_samples[, t], probs = 1 - alpha / 2, na.rm = TRUE)
}
return(list(lower = lower, upper = upper))
}
# Main execution
set.seed(123)
n <- 1000
theta <- 0.2
mu <- 1
sigma2 <- 0.1
omega2 <- 0.5
# Simulate data
Y <- simulate_ou_process(n, theta, mu, sigma2, omega2)
# Check data validity
if (any(!is.finite(Y))) stop("Data Y contains non-finite values.")
# Estimate parameters
res <- estimate_parameters(Y)
res
params_hat <- res$par
# Bootstrap prediction intervals
prediction_intervals <- bootstrap_prediction_interval(Y, params_hat, B = 1000, alpha = 0.05)
# Plot prediction intervals
time <- 2:length(Y)
plot(time, Y[-1], type = "l", col = "blue", ylab = "Y_t", xlab = "Time", main = "Bootstrap Prediction Intervals")
lines(
time,
simulate_ou_process(999, params_hat[1], params_hat[2], params_hat[3], params_hat[4]),
col = "red",
lty = 2
)
lines(time, prediction_intervals$lower, col = "red", lty = 2)
lines(time, prediction_intervals$upper, col = "red", lty = 2)
legend("topleft", legend = c("Y_t", "Prediction Interval"), col = c("blue", "red"), lty = c(1, 2))
remotes::install_github("stan-dev/posteriordb-r")
library(posteriordb)
my_pdb <- pdb_local()
my_pdb <- pdb_local("./posteriordb")
pos <- posterior_names(my_pdb)
head(pos)
head(pos)
pos
my_pdb <- pdb_local("./posteriordb")
pos <- posterior_names(my_pdb)
head(pos)
pos
library(rstan)
library(posteriordb)
library(rstan)
# Set the environment variable PDB_PATH to your local posteriordb repo as
Sys.setenv(PDB_PATH = "./posteriordb")
# We setup a connection to the local posteriordb
pdbl <- pdb_local()
library(posteriordb)
library(rstan)
# MeteInfo
R <- "1"
MODEL_NAME <- sprintf("test-laplace_%s", R)
# Add Data
Sys.setenv(PDB_PATH = "../posteriordb")
pdbl <- pdb_local()
setwd("C:/Users/w-cy/Code/RProjects/add_distributions/laplace_1")
library(posteriordb)
library(rstan)
# MeteInfo
R <- "1"
MODEL_NAME <- sprintf("test-laplace_%s", R)
# Add Data
Sys.setenv(PDB_PATH = "../posteriordb")
pdbl <- pdb_local()
x_data <- list(name = MODEL_NAME,
keywords = c("test_laplace"),
title = sprintf("A Test Data for the Laplacian %s Model", R),
description = sprintf("The data contain data for Laplacian %s Model.", R),
urls = NULL,
references = NULL,
added_date = Sys.Date(),
added_by = "Congye Wang")
di <- as.pdb_data_info(x_data)
laplace <- list(N = as.integer(2), r = as.double(R))
dat <- as.pdb_data(laplace, info = di)
write_pdb(dat, pdbl, overwrite = TRUE)
# Add model
x_model <- list(name = MODEL_NAME,
keywords = c("test_laplace"),
title = sprintf("A Test Data for the Laplacian %s Model", R),
description = sprintf("The data contain data for Laplacian %s Model.", R),
urls = NULL,
framework = "stan",
references = NULL,
added_by = "Congye Wang",
added_date = Sys.Date())
mi <- as.pdb_model_info(x_model)
smc <- "
data {
int<lower=1> N;
real r;
}
parameters {
vector[N] x;
}
model {
target += -norm2(x)^r;
}
"
mc <- as.model_code(smc, info = mi, framework = "stan")
write_pdb(mc, pdbl)
# Add Posterior
x_posterior <- list(pdb_model_code = mc,
pdb_data = dat,
keywords = c("test_laplace"),
urls = NULL,
references = NULL,
dimensions = list("x" = 2),
reference_posterior_name = sprintf("%s-%s", MODEL_NAME, MODEL_NAME),
added_date = Sys.Date(),
added_by = "Congye Wang")
po <- as.pdb_posterior(x_posterior)
write_pdb(po, pdbl)
# Add Posterior Reference Draws
po <- posterior(sprintf("%s-%s", MODEL_NAME, MODEL_NAME), pdbl)
po$dimensions <- list("x" = 2)
## Setup reference posterior info ----
x_draw <- list(name = posterior_name(po),
inference = list(method = "stan_sampling",
method_arguments = list(chains = 10,
iter = 20000,
warmup = 10000,
thin = 10,
seed = 4711,
control = list(adapt_delta = 0.92))),
diagnostics = NULL,
checks_made = NULL,
comments = sprintf("This is a test reference posterior for the Laplacian %s Model", R),
added_by = "Congye Wang",
added_date = Sys.Date(),
versions = NULL)
rpi <- as.pdb_reference_posterior_info(x_draw)
rp <- compute_reference_posterior_draws(rpi, pdbl)
rp <- check_reference_posterior_draws(x = rp)
write_pdb(rp, pdbl, overwrite = TRUE)
# Check
check_pdb_posterior(po)
